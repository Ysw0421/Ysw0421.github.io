---
layout: post
title: Flume Testing
meta: Concept
category: IoT
comments: true
---
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-dark.min.css">
    <link rel="stylesheet" type="text/css" href="/css/pageframe.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <style>
      @import url(//fonts.googleapis.com/earlyaccess/nanumpenscript.css);
    </style>
  <!--
  수식용 스크립트 MathJax
  -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      //jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
      //,
      //displayAlign: "left",
      //displayIndent: "2em"
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
  </head>
  <body>	  
<!--
카테고리: Categories <h3 class="Categories BasicFontSet"></h3>
날짜: Date 
      {% for news in site.categories.analysis %}
        {% if news.title == 'Testing css'%}
          <a class="Date">{{ news.date | date_to_string }}</a> | <a class="post-tag">{{ page.category }}</a>
        {% endif %}
      {% endfor %}
태그: Tags <a class="post-tag">태그 내용</a>
posting한곳: Posting <blockquote><p class="posting">포스팅 </p></blockquote>
주제: MainTitle <h1 class="BasicFontSet"></h1>
소제: SubTitle <h2 class="BasicFontSet"></h2>
단락: Paragraph <p class="Paragraph"></p>
내용: Contents <p class="Contents"></p>
이미지: Imgsize - media query 적용
이미지 text: Imgtext
      <p class="Imgtext">
          <img src="이미지 주소" class="concept"></br>
          <내용></br>
      </p>
전체 코드 URL: CodeURL
참고자료: Reference <blockquote><p class="Reference">가져온곳: <a class="Reference"> URL</a></p>
-->
      <a>
	<h3 class="Categories BasicFontSet">Flume Testing</h3>
	{% for news in site.categories.IoT %}
        {% if news.title == 'Flume Testing'%}
          <a class="Date">{{ news.date | date_to_string }}</a> | <a class="post-tag" href="https://ysw0421.github.io/contents/projects/#IoT">{{ page.category }}</a>
        {% endif %}
        {% endfor %}
     </a>
	<blockquote><p class="posting">포스팅 </p></blockquote>
<h2 class="BasicFontSet">Apache Flume</h2>
<p class="Paragraph">Implementation Component of Flume Component</p>
      <p class="Imgtext">
          <img src="/asset/Project/IoTMiddleware/DataCollectionService/Flume/Flume6.jpg" class="concept"></br>
          <Flume 구성 요소의 구현 컴포넌트></br>
      </p>
	</br>
	데이터 소스는 사용자 정의가 가능하기 때문에 Flume은 네트워크 트래픽 데이터, 소셜 미디어 생성 데이터, 전자 메일 메시지 및 거의 모든 데이터 소스를 포함하여 
	대량의 이벤트 데이터를 전송하는 데 사용할 수 있습니다.</br>
	</br>
	Flume은 인공수로, 용수로 등의 사전적의미를 가진다.
	Apache Flume은 로그(통나무)의 이중적인 의미에서 착안한 멋진 비유입니다. 
	통나무를 운반하는 수로의 이미지로 여러 서버로부터 로그를 수집하고 모으는 스트리밍 로그 수집기 기술을 설명하는, 딱 맞는 이름입니다.

	Apache Flume과 벌목장 플룸을 다음과 같이 표현으로 설명할 수 있습니다.
<table>
  <thead>
    <tr>
      <th class="TableFont" style="text-align: center">Apache Flume</th>
      <th class="TableFont" style="text-align: center">벌목장 Flume</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Apache Flume이란</td>
      <td style="text-align: center">전통적인 벌목장의 플룸이란</td>
    </tr>
    <tr>
      <td style="text-align: center">여러 서버에</td>
      <td style="text-align: center">여러 벌목장에</td>
    </tr>
    <tr>
      <td style="text-align: center">설치되는 소프트웨어로</td>
      <td style="text-align: center">설치되는 통나무 운반용 수로(플룸)로</td>
    </tr>
    <tr>
      <td style="text-align: center">수집한 로그를</td>
      <td style="text-align: center">벌목한 통나무(로그)를</td>
    </tr>
    <tr>
      <td style="text-align: center">원격지의 Data Lake로</td>
      <td style="text-align: center">산 아래 강으로</td>
    </tr>
    <tr>
      <td style="text-align: center">전송하는 비동기 채널입니다.</td>
      <td style="text-align: center">운반하는 수로입니다.</td>
    </tr>
  </tbody>
</table>
	</br>
	벌목장의 플룸의 이미지로 부터 우리는 다음과 같은 Apache Flume의 기술적인 특징을 유추할 수 있습니다.</br>
	1. 분산환경에서 로그를 모으는 소프트웨어다. (벌목장과 강이 멀리 떨어진..)</br>
	2. 여러곳에 위치하는 로그를 한 곳으로 모을 수 있다.</br>
	3. 로그를 배치로 한꺼번에 보내는 것이 아니라 스트리밍하게 지속적으로 보낸다.</br>
	4. 비동기 방식으로 처리한다.</br>
	5. 로그를 수집하는 역할과 로그를 전송하는 역할은 개별적으로 움직인다. (Source와 Sink는 개별적인 Thread임)</br>
	</br>
	여러 서비스 제공 서버에 산재해 있는 로그들을 하나의 로그 수집서버로 모으는 역할을 수행해야하는 수집기로서 어울리는 이름이다.
	전형적인 Converging Flow(??)의 구조로 구성되는 Flume은 스트림 지향의 데이터 플로우를 기반으로 하며 
	지정된 모든 서버로부터 로그를 수집한 후 하둡 HDFS와 같은 중앙 저장소에 적재하여 분석하는 시스템을 구축해야할 때 적합하다.
	Flume은 아래 4가지 사항에 대한 핵심사항을 만족시키도록 설계되었으며 이를 바탕으로 최신 아파치 오픈소스 버전을 제공하고 있다.</br>
	</br>
	<b>시스템 신뢰성</b>$(Reliability)$ - 장애가 발생시 로그의 유실없이 전송할 수 있는 기능</br>
	<b>시스템 확장성</b>$(Scalability)$ - Agent의 추가 및 제거가 용이, Scale-up/Scale-out 방식의 확장을 모두 지원</br>
	<b>관리 용이성</b>$(Manageability)$ - 간결한 구조로 관리가 용이</br>
	<b>기능 확장성</b>$(Extensibility)$ - 새로운 기능을 쉽게 추가할 수 있음</br>
	</br>
	클라우데라에서 개발하던 0.x 버전을 Flume OG 라고 지칭하며 
	아파치 오픈소스로 이관된 이후의 1.X 버전을 Flume NG라고 부른다.
	Flume OG에서 Agent, Collector, Master로 구분되어지던 아키텍쳐 구조가 
	Flume NG에서 하나의 Agent로 통합되어 단순해졌으며 이전 버전보다 기능은 줄어들었지만 단순한 구조로 인해 확장성과 자유도가 높아서 훨씬 유연하게 업무에 적용 가능해졌다.
	Google 검색을 통해 Flume 관련 정보를 검색하면 아직까지도 Flume OG에 대한 내용이 훨씬 많이 조회되지만 프로젝트를 시작할 당시에 비해
	지금은 Flume NG 관련 정보가 많이 확인이 된다.</br>
      <p class="Imgtext">
          <img src="/asset/Project/IoTMiddleware/DataCollectionService/Flume/Flume1.png" class="concept" style="50%"></br>
          <Flume NG 기본 아키텍쳐></br>
      </p>
	Flume NG는 하나의 Agent로 구성되는데 Agent는 내부적으로 Source와 Sink 그리고 Channel로 구성된다.</br>
	</br>
	$1. Source$ - Event를 받아 입력된 정보를 Sink로 전달한다.</br>
	$2. Channel$ - Source와 Sink의 Dependency를 제거하고 장애에 대비하기 위해 중간 채널을 제공하며 
	   Source는 Channel에 Event 정보를 저장하며 Sink는 채널로부터 정보를 전달받아 처리한다.</br>
	$3. Sink$ - 채널로부터 Source가 전달한 Event 정보를 하둡 HDFS에 저장하거나 다음 Tier의 Agent 또는 DB로 전달한다.
	   지정된 프로토콜의 Type에 따른 처리를 진행한다.</br>
	</br>

<h2 class="BasicFontSet">Flume Converging Flow</h2>
      <p class="Imgtext">
          <img src="/asset/Project/IoTMiddleware/DataCollectionService/Flume/Flume2.jpg" class="concept" style="width:50%"></br>
          <HDFS Direct 연동></br>
      </p>
	각 서버의 로그를 수집하기 위해 HDFS로 직접 연결시 각 서버마다 연동을 위해 복잡한 코드들과 지속적인 관리가 필요하다.
	유지보수 비용 측면이나 확장성 관점에 추천할 수 없는 구조이다.</br>
      <p class="Imgtext">
          <img src="/asset/Project/IoTMiddleware/DataCollectionService/Flume/Flume3.png" class="concept" style="width:50%"></br>
          <Single Flume Agent 연동></br>
      </p>
	로그 수집의 권한을 Flume으로 위임함으로써 각 서버들은 고객들에게 기존보다 빠른 서비스를 제공할 수 있다.
	하나의 Flume Agent가 로그를 수집함으로써 Flume Agent의 장애 발생시 로그수집이 중단될 수 있는 문제가 존재한다.</br>
      <p class="Imgtext">
          <img src="/asset/Project/IoTMiddleware/DataCollectionService/Flume/Flume4.png" class="concept" style="width:50%"></br>
          <Multi Flume Agent 연동></br>
      </p>
	장애 발생시 최소한의 투자비용으로 가용성을 확보할 수 있다.
	장애로 인해 Flume Agent가 중지되더라도 백업 Agent를 통해 계속 로그 수집을 진행할 수 있다.
	장애 대응을 위한 Failover나 로그 Event 정보를 분산하기 위한 Load balance 기능등 상황에 맞게 적용하면 된다.</br>
      <p class="Imgtext">
          <img src="/asset/Project/IoTMiddleware/DataCollectionService/Flume/Flume5.jpg" class="concept"></br>
          <대량 로그를 처리를 위한 일반적인 구조></br>
      </p>
	100개 이상의 서버로부터 대량의 로그를 수집할 경우 여러 단계의 Tier를 구성하여 로그를 수집한다.
	하나의 Flume Agent로 로그가 집중됨으로서 서버 부하 발생 및 러리 지연을 방지하기 위해 Tier별로 구성하여 처리한다.
	하지만, 각 시스템 상황에 맞춰 Flume Agent의 Tier를 구성할 필요가 있다.</br>

<h2 class="BasicFontSet">Flume 설치</h2>
	Flume 설치 파일은 다음 URL에서 다운로드 할 수 있습니다. 2019.01 현재 최신버전은 1.9.0입니다. 설치 파일은 gz파일 형태로 배포됩니다.</br>
	https://flume.apache.org/download.html</br>
	설치는 압축을 푸는 것으로 완료됩니다.
	</br>
	</br>
	</br>
<pre><code>
$ sudo wget http://www.apache.org/dyn/closer.lua/flume/1.9.0/apache-flume-1.9.0-bin.tar.gz
$ cd /usr/local/lib
$ sudo tar -zxvf apache-flume-1.8.0-bin.tar.gz
$ sudo mv apache-flume-1.8.0 flume
</code></pre>
	</br>
	</br>
	Flume 설치 디렉터리 /usr/local/lib/flume로 가정합니다.
	이 디렉터리는 아래에서 <b>{FLUME_HOME}</b>으로 참조하겠습니다.</br>
	</br>
	</br>
<h2 class="BasicFontSet">Flume 기본 설정과 실행 방법</h2>
	Flume으로 서버로그를 Hadoop에 수집하는 예제를 소개합니다. 
	Flume은 에이전트 노드와 컬렉트 노드에 설치되었음을 가정합니다.</br>
<그림 1.></br>
<b>Agent Node</b></br>
	로그가 발생하는 서버</br>
	WAS 로그가 저장되는 디렉터리를 spooling 하여 로그 메모리 채널에 전송</br>
	Avro Sink가 채널의 로그를 Collecting node로 전송</br>
	port: 4545</br>
<b>Collecting node</b></br>
	Avro Source : Server A로부터 Avro통신을 통해 로그 수집하여 메모리 채널에 전달</br>
	HDFS Sink : 수집된 이벤트를 HDFS에 저장</br>
<p class="Paragraph">Agent 노드 Flume 설정 및 실행</p>
	로그를 수집하는 에이전트 노드에 다음과 같은 Flume 설정을 추가합니다. 
	파일명은 flume.conf입니다. 
	다음 예제는 /data/waslogs에 추가되는 로그 파일을 컬렉트 노드에 전송하는 설정입니다. 
	전송 포맷은 avro입니다.</br>
	</br>
	이 설정 파일은 /usr/local/lib/flume/conf에 하는 것으로 가정합니다.</br>
<코드 1.></br>
	에이전트 노드의 flume은 다음과 같은 명령으로 실행됩니다.</br>
<코드 2.></br>
	</br>
	</br>
<p class="Paragraph">Collecting 노드 Flume 설정 및 실행</p>
	다음은 컬렉트 노드의 flume 설정입니다. 
	avro 포멧으로 유입되는 로그를 수집항 hadoop에 저장하는 구성입니다. 
	파일명은 flume.conf입니다. 이 설정 파일은 /usr/local/lib/flume/conf에 하는 것으로 가정합니다.</br>
	<코드 3.></br>
	에이전트 노드의 flume은 다음과 같은 명령으로 실행됩니다.</br>
	<코드 4.></br>
<h2 class="BasicFontSet">Flume의 유연한 구성 그리고 Kafka </h2>
<h2 class="BasicFontSet">Flume 모니터링</h2>
	<blockquote><p class="Reference">가져온곳: <a class="Reference"> http://www.nextree.co.kr/p2704/
		http://taewan.kim/post/flume_images/</a></p></blockquote>
  </body>
</html>
